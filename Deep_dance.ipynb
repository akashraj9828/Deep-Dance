{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_dance.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOFfBClSr7hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip3 install keras\n",
        "! pip3 install ann_visualizer\n",
        "! pip install graphviz\n",
        "! pip install h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrO8fft8j4qV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas import read_csv\n",
        "import numpy as np\n",
        "import keras\n",
        "import os, sys\n",
        "from IPython.display import display\n",
        "from IPython.display import Image as _Imgdis\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from time import time\n",
        "from time import sleep\n",
        "from scipy import ndimage\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from shutil import rmtree\n",
        "import os\n",
        "import gc\n",
        "from keras.layers import BatchNormalization,Activation,MaxPooling2D,AveragePooling2D,Flatten,Dense,Dropout,Input,Conv2D,UpSampling2D,Reshape,Conv2DTranspose\n",
        "from keras.models import Sequential,Model,model_from_json,load_model\n",
        "from keras.layers import LSTM,Dropout,InputLayer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6pbapJkqn3w",
        "colab_type": "text"
      },
      "source": [
        "> ## Helper function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSbX9z0VsOuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ann_visualizer.visualize import ann_viz;\n",
        "from keras.models import model_from_json\n",
        "\n",
        "def visualize_model(model,is_json=False,):\n",
        "  if is_json:\n",
        "    m = model_from_json(model)\n",
        "    ann_viz(m, title=\"Model Visualization\")\n",
        "  else:\n",
        "      ann_viz(model, title=\"Model Visualization\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7PQa4dQeZSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_dense(x,epoch):\n",
        "  n=9\n",
        "  pr=3\n",
        "  fig_size=(20,20)\n",
        "  fig = plt.figure(figsize=fig_size)\n",
        "  for i in range(n):\n",
        "    ar=x[i]\n",
        "    p=[]\n",
        "    p.append(ar)\n",
        "    p.append(ar)\n",
        "    p.append(ar)\n",
        "    a1 = fig.add_subplot(n/pr,n/pr, i+1)\n",
        "    a1.imshow(p,cmap='gray')\n",
        "    a1.get_xaxis().set_visible(False)\n",
        "    a1.get_yaxis().set_visible(False)\n",
        "#     plt.show()\n",
        "  plt.close()\n",
        "  fig.savefig(\"{}/dense/{}.png\".format(path,epoch))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFBMD9JL60kT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #### USE WITH CAUTION ###### #\n",
        "# use only when needed to reset the progress and start over again\n",
        "#this function resets the workin directory\n",
        "from shutil import rmtree\n",
        "import os\n",
        "\n",
        "def reset(path,make_other_dir=True):\n",
        "  \n",
        "  if make_other_dir==True:\n",
        "    acc = path+\"/acc\" \n",
        "    loss=path+\"/loss\"\n",
        "    out=path+\"/out\" \n",
        "    dense=path+'/dense'\n",
        "    folder_list=[acc,out,loss,dense]\n",
        "  else:\n",
        "    p='/'.join(path.split('/')[:-1])\n",
        "    p1=p+'/rnn'\n",
        "    p2=p+'/aec'\n",
        "    p3=p+'/dataset'\n",
        "    folder_list=[p,p1,p2,p3]\n",
        "    \n",
        "  print(folder_list)\n",
        "  conformation=input(\"do you really want to delete all folders i.e acc,loss,out (Y/N)?\")\n",
        "  if conformation == 'Y' or conformation == 'y':\n",
        "    for f in folder_list:\n",
        "      try:\n",
        "        rmtree(f,ignore_errors=False)\n",
        "      except:\n",
        "        pass\n",
        "      try:\n",
        "        os.mkdir(f)\n",
        "      except:\n",
        "        pass\n",
        "    print(\"reset sucessfull :\"+str(folder_list))\n",
        "\n",
        "      \n",
        "    \n",
        "# reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XYuBTVow_R2",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "load_dataset_from_npy = True \n",
        "load_saved_model=False  \n",
        "\n",
        "path = F\"ai_dance_models/ai_dance_128_dims/aec\" \n",
        "img_path = F\"dataset/480_cleaned_14k_800x480/\"\n",
        "dataset_path=F\"dataset/dataset.npy\"\n",
        "dense_dataset_path=F\"dataset/dense_dataset.npy\"\n",
        "model_path=path+\"/model_weight.h5\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVascstG-IQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make all the folders\n",
        "# ignore if you downloaded the data already\n",
        "os.mkdir('ai_dance_models')\n",
        "reset(path,False)\n",
        "reset(path,True)\n",
        "os.mkdir('dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc3nA3OOeAoa",
        "colab_type": "text"
      },
      "source": [
        "> ## Loading dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap25F9eaJhG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# //load data driectly from images or .npy file.\n",
        "\n",
        "# Original Dimensions\n",
        "image_height = 480\n",
        "image_width = 800\n",
        "compression_ratio = 4\n",
        "\n",
        "image_width = int(image_width / compression_ratio)\n",
        "image_height = int(image_height / compression_ratio)\n",
        "\n",
        "channels = 1\n",
        "\n",
        "dataset=None\n",
        "if load_dataset_from_npy==True:\n",
        "  dataset=np.load(dataset_path)\n",
        "  print(\"Data loaded \\nDataset shape: {}\".format(dataset.shape))\n",
        "else:\n",
        "  folder = img_path\n",
        "  onlyfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
        "  print(\"Working with {0} images\".format(len(onlyfiles)))\n",
        "  print(onlyfiles[:10])\n",
        "\n",
        "  train_files = []\n",
        "  for _file in onlyfiles:\n",
        "      train_files.append(_file)\n",
        "  train_files.sort()\n",
        "\n",
        "  print(\"Files in train_files: {}\".format(len(train_files)))\n",
        "\n",
        " \n",
        "\n",
        "  dataset = np.ndarray(shape=(len(train_files), image_height, image_width,channels,),\n",
        "                       dtype=np.float32)\n",
        "\n",
        "  i = 0\n",
        "  for _file in train_files:\n",
        "      img = load_img(folder + \"/\" + _file,color_mode='grayscale')  # this is a PIL image\n",
        "      img.thumbnail((image_width, image_height))\n",
        "      x = img_to_array(img)  \n",
        "      x = x.reshape((image_height, image_width,channels))\n",
        "      x=x/255\n",
        "      dataset[i] = x\n",
        "      i += 1\n",
        "      if i % 250 == 0:\n",
        "          print(\"%d images to array\" % i)\n",
        "  print(\"All images to array!\")\n",
        "  print('saved array to ',dataset_path)\n",
        "  np.save(dataset_path,dataset)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmTRBj4mTmju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check sample image\n",
        "n=random.randint(0,len(dataset))\n",
        "img=np.reshape(dataset[n],(image_height,image_width))\n",
        "plt.imshow(img,cmap='gray')\n",
        "plt.title(\"BnW image(input)\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nAaydaFQeJEd",
        "colab": {}
      },
      "source": [
        "from keras.layers import BatchNormalization,Activation,MaxPooling2D,AveragePooling2D,Flatten,Dense,Dropout,Input,Conv2D,UpSampling2D,Reshape,Conv2DTranspose\n",
        "from keras.models import Sequential,Model,model_from_json,load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp1o6015hESC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filters=32\n",
        "encoded_dims=128\n",
        "def Encoder():\n",
        "  \n",
        "  inputshape=dataset[0].shape\n",
        "  input_img= Input(shape=(inputshape))\n",
        "  x = Conv2D(filters,(3,3), padding='same')(input_img)\n",
        "  x=Activation('relu')(x)\n",
        "  x = Conv2D(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "  \n",
        "  x = MaxPooling2D((2,2), padding='same')(x)\n",
        "  x = Conv2D(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x = Conv2D(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "  \n",
        "  x = MaxPooling2D((2,2), padding='same')(x)\n",
        "  x = Conv2D(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x = Conv2D(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "  \n",
        "  x = MaxPooling2D((2,2), padding='same',)(x)\n",
        "  x = Conv2D(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x = Conv2D(8,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "\n",
        "  x=Flatten()(x)\n",
        "  x=Dense(512)(x)\n",
        "  x=Activation('relu')(x)\n",
        "\n",
        "\n",
        "  x=Dense(encoded_dims)(x)\n",
        "  x=Activation('relu')(x)\n",
        "\n",
        "  encoder=Model(input_img,x)\n",
        "  return encoder\n",
        "\n",
        "\n",
        "def Decoder():\n",
        "  \n",
        "  inp=Input(shape=(encoded_dims,))\n",
        "  x=Dense(512)(inp)\n",
        "  x=Activation('relu')(x)\n",
        "\n",
        "  x=Dense(1500, )(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x=Reshape(( 15, 25, 4))(x)\n",
        "  \n",
        "  x = Conv2DTranspose(4,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x = Conv2DTranspose(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "\n",
        "  x = UpSampling2D((2,2))(x)\n",
        "  x = Conv2DTranspose(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x = Conv2DTranspose(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "\n",
        "  x = UpSampling2D((2,2))(x)\n",
        "  x = Conv2DTranspose(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x = Conv2DTranspose(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "\n",
        "  x = UpSampling2D((2,2))(x)\n",
        "  x = Conv2DTranspose(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x = Conv2DTranspose(filters,(3,3), padding='same')(x)\n",
        "  x=Activation('relu')(x)\n",
        "  x = Conv2DTranspose(1, (3, 3), padding='same')(x)\n",
        "  x=Activation('sigmoid')(x)\n",
        "\n",
        "  decoder=Model(inp,x)\n",
        "  return decoder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlDPtA3JBoSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder=None\n",
        "decoder=None\n",
        "autoencoder=None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K_R7K5BvWjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# temp block\n",
        "dataset=np.random.rand(14401,120,200,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b0doCPXhXvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if load_saved_model==False:\n",
        "  inp=Input(shape=(dataset[0].shape))\n",
        "  encoder=Encoder()\n",
        "  decoder=Decoder()\n",
        "  autoencoder = Model(inp, decoder(encoder(inp)))\n",
        "  autoencoder.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\n",
        "#   autoencoder.compile(optimizer='rmsprop', loss='mse',metrics=['accuracy'])\n",
        "\n",
        "  # save model architecture to json\n",
        "  with open('{}/autoencoder.json'.format(path), 'w') as f:\n",
        "    f.write(autoencoder.to_json())\n",
        "  with open('{}/encoder.json'.format(path), 'w') as f:\n",
        "    f.write(encoder.to_json())\n",
        "  with open('{}/decoder.json'.format(path), 'w') as f:\n",
        "    f.write(decoder.to_json())\n",
        "\n",
        "#   encoder.summary()          \n",
        "#   decoder.summary()\n",
        "  autoencoder.summary()\n",
        "\n",
        "  # # visualize model\n",
        "  from IPython.display import SVG\n",
        "#   from keras.utils.vis_utils import model_to_dot\n",
        "  from keras.utils import plot_model\n",
        "\n",
        "#   SVG(model_to_dot(autoencoder,show_shapes=True,show_layer_names=True,rankdir=\"TD\").create(prog='dot', format='svg'))\n",
        "  plot_model(encoder,show_shapes=True, to_file=path +'/encoder.png')\n",
        "  plot_model(decoder,show_shapes=True, to_file=path +'/decoder.png')\n",
        "  plot_model(autoencoder,show_shapes=True, to_file=path +'/autoencoder.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i74sSDV44-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "import json\n",
        "encoder=None\n",
        "decoder=None\n",
        "autoencoder=None\n",
        "if load_saved_model==True:\n",
        "  encoder=load_model(path+'/encoder_weight.h5')\n",
        "  decoder=load_model(path+'/decoder_weight.h5')\n",
        "  autoencoder=load_model(path+'/../../ai_dance_aec_128_dims/autoencoder_weight.h5')\n",
        "  encoder.summary()\n",
        "  decoder.summary()\n",
        "  autoencoder.summary()\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taU4d5mhxqJz",
        "colab_type": "text"
      },
      "source": [
        "> ## Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2st9RsfAwwlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# suffix='autoencoder 128 dims'\n",
        "suffix=''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UvbqNAI3eJEl",
        "colab": {}
      },
      "source": [
        "# used to log training stats \n",
        "from keras.callbacks import Callback\n",
        "\n",
        "plot_after=1\n",
        "show_after=100\n",
        "save_after=1\n",
        "class MyLogger(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "      self.i = 0\n",
        "      self.x = []\n",
        "      self.losses = []\n",
        "      self.val_losses = []\n",
        "      self.acc = []\n",
        "      self.val_acc = []\n",
        "      self.logs = []\n",
        "      self.max_acc=-9999\n",
        "      self.max_val_acc=-9999\n",
        "      self.min_loss=9999\n",
        "      self.min_val_loss=9999\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      self.update_value(logs)\n",
        "      self.plot_graph(epoch)\n",
        "      self.save_model(logs,epoch)\n",
        "      self.write_log(logs,epoch)  \n",
        "\n",
        "      \n",
        "    def write_log(self,logs,epoch):\n",
        "      with open('{}/log.txt'.format(path), 'a+') as f:\n",
        "          f.write('\\n#{} : {}'.format(epoch, logs))\n",
        "          \n",
        "    def update_value(self,logs):\n",
        "      self.logs.append(logs)\n",
        "      self.x.append(self.i)\n",
        "      self.losses.append(logs.get('loss'))\n",
        "      self.val_losses.append(logs.get('val_loss'))\n",
        "      self.acc.append(logs.get('acc'))\n",
        "      self.val_acc.append(logs.get('val_acc'))\n",
        "      self.i += 1\n",
        "    \n",
        "      self.min_loss = min(logs.get('loss'),self.min_loss)\n",
        "      self.min_val_loss = min(logs.get('val_loss') ,self.min_val_loss)\n",
        "      self.max_acc = max(logs.get('acc'),self.max_acc)\n",
        "      self.max_val_acc = max(logs.get('val_acc') ,self.max_val_acc)\n",
        "\n",
        "    def plot_graph(self,epoch):\n",
        "#     loss and accuracy plotting\n",
        "      if epoch%plot_after==0:\n",
        "        # LOSS         \n",
        "        plt.plot(self.x, self.losses, label=\"loss\")\n",
        "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
        "        plt.legend()\n",
        "        plt.savefig(\"{}/loss/graph_loss{}.png\".format(path,suffix))\n",
        "#         plt.show();\n",
        "        plt.close()\n",
        "        # ACC\n",
        "        plt.plot(self.x, self.acc, label=\"acc\")\n",
        "        plt.plot(self.x, self.val_acc, label=\"val_acc\")\n",
        "        plt.legend()\n",
        "        plt.savefig(\"{}/acc/graph_acc{}.png\".format(path,suffix))\n",
        "#         plt.show();\n",
        "        plt.close()\n",
        "  \n",
        "#     Output saving\n",
        "      dense=encoder.predict_on_batch(testd)\n",
        "      print(dense[0])\n",
        "      plot_dense(dense,epoch)\n",
        "      pre=decoder.predict_on_batch(dense)\n",
        "      fig = plt.figure(figsize=fig_size)\n",
        "      for i in range(0,n):\n",
        "        a1 = fig.add_subplot(n/pr,n/pr, i+1)\n",
        "        p=a1.imshow(np.reshape(pre[i],(image_height,image_width),),cmap='gray')\n",
        "        a1.get_xaxis().set_visible(False)\n",
        "        a1.get_yaxis().set_visible(False)\n",
        "#       if epoch%show_after==0:\n",
        "#         print(\"*\"*20,'RECREATION ',epoch,'*'*20)\n",
        "#         plt.show()\n",
        "#         print(\"*\"*50)        \n",
        "      plt.close()\n",
        "      fig.savefig(\"{}/out/{}.png\".format(path,epoch))\n",
        "    \n",
        "    \n",
        "    \n",
        "    def save_model(self,logs,epoch):\n",
        "      if epoch%save_after==0:\n",
        "        autoencoder.save(\"{}/autoencoder_weight_{}.h5\".format(path,suffix))\n",
        "        encoder.save(\"{}/encoder_weight_{}.h5\".format(path,suffix))\n",
        "        decoder.save(\"{}/decoder_weight_{}.h5\".format(path,suffix))\n",
        "      #saves best model:\n",
        "      if logs.get('acc')==self.max_acc:\n",
        "        autoencoder.save(\"{}/autoencoder_best_acc_{}.h5\".format(path,suffix))\n",
        "        encoder.save(\"{}/encoder_best_acc_{}.h5\".format(path,suffix))\n",
        "        decoder.save(\"{}/decoder_best_acc_{}.h5\".format(path,suffix)) \n",
        "      if logs.get('val_acc')==self.max_val_acc:\n",
        "        autoencoder.save(\"{}/autoencoder_best_val_acc_{}.h5\".format(path,suffix,suffix))\n",
        "        encoder.save(\"{}/encoder_best_val_acc_{}.h5\".format(path,suffix))\n",
        "        decoder.save(\"{}/decoder_best_val_acc_{}.h5\".format(path,suffix))  \n",
        "      if logs.get('loss')==self.min_loss:\n",
        "        autoencoder.save(\"{}/autoencoder_least_loss_{}.h5\".format(path,suffix))\n",
        "        encoder.save(\"{}/encoder_least_loss_{}.h5\".format(path,suffix))\n",
        "        decoder.save(\"{}/decoder_least_loss_{}.h5\".format(path,suffix)) \n",
        "      if logs.get('val_loss')==self.min_val_loss:\n",
        "        autoencoder.save(\"{}/autoencoder_least_val_loss_{}.h5\".format(path,suffix))\n",
        "        encoder.save(\"{}/encoder_least_val_loss_{}.h5\".format(path,suffix))\n",
        "        decoder.save(\"{}/decoder_least_val_loss_{}.h5\".format(path,suffix))\n",
        "          \n",
        "# correct one"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4IJfEeBx1xy",
        "colab_type": "text"
      },
      "source": [
        "> ## Training AUTOENCODER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoXjPni-AWao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset(path)\n",
        "\n",
        "# save 9 sample images for comparison\n",
        "n=9\n",
        "pr=3\n",
        "fig_size=(10,10)\n",
        "rand=[randint(0,3755) for i in range(n)]\n",
        "testd=[dataset[rand[i]] for i in range(n) ]\n",
        "testd = np.asarray(testd, dtype=np.float32)\n",
        "start=0\n",
        "fig = plt.figure(figsize=fig_size)\n",
        "for i in range(n):\n",
        "  a1 = fig.add_subplot(n/pr,n/pr, i+1)\n",
        "  p=a1.imshow(np.reshape(testd[i],(image_height,image_width),),cmap='gray')\n",
        "  a1.get_xaxis().set_visible(False)\n",
        "  a1.get_yaxis().set_visible(False)\n",
        "plt.close()\n",
        "fig.savefig(\"{}/out/orignal_.png\".format(path))\n",
        "fig.savefig(\"{}/out/000_orignal_.png\".format(path))\n",
        "\n",
        "      \n",
        "# callbacks   \n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau,CSVLogger,LambdaCallback\n",
        "cbk=MyLogger()\n",
        "bva= ModelCheckpoint(path+'/aec_best_val_acc_'+suffix+'.h5', monitor='val_acc', mode='max',save_best_only=True, save_weights_only=False)\n",
        "bvl= ModelCheckpoint(path+'/aec_least_val_loss_'+suffix+'.h5', monitor='val_loss', mode='min',save_best_only=True, save_weights_only=False)\n",
        "ba= ModelCheckpoint(path+'/aec_best_acc_'+suffix+'.h5', monitor='acc', mode='max',save_best_only=True, save_weights_only=False)\n",
        "bl= ModelCheckpoint(path+'/aec_least_loss_model_'+suffix+'.h5', monitor='loss', mode='min',save_best_only=True, save_weights_only=False)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.1,\n",
        "                              patience=20, min_lr=0.0001,verbose=1)\n",
        "csv_logger = CSVLogger(path+'/training.csv')\n",
        "batch_size = 128\n",
        "num_epoch = 1000\n",
        "data=dataset\n",
        "\n",
        "model_log = autoencoder.fit(data, data,\n",
        "            batch_size=batch_size,\n",
        "            epochs=num_epoch,\n",
        "            verbose=1,\n",
        "            validation_split=0.1,\n",
        "            callbacks=[cbk,bva,bvl,ba,bl,reduce_lr,csv_logger],\n",
        "            initial_epoch=0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcvEAI6T6cxX",
        "colab_type": "code",
        "outputId": "0164f32f-b005-4666-9b32-6a090df3c43e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoded_data=None\n",
        "# encoded_dims=128\n",
        "encoded_data=np.ndarray([])\n",
        "\n",
        "for i in range(0,14401,500):\n",
        "  x=encoder.predict_on_batch(dataset[i:i+500])\n",
        "  encoded_data=np.append(encoded_data,x)\n",
        "encoded_data=np.reshape(encoded_data[1:],(dataset.shape[0],encoded_dims))\n",
        "np.save(dense_dataset_path,encoded_data)\n",
        "encoded_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14401, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0WvYH0g77qD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_data[1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTKMc39A7gBe",
        "colab_type": "text"
      },
      "source": [
        "> ## RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g91tbX3e7o_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_dataset_from_npy = True \n",
        "load_saved_model=False  \n",
        "\n",
        "path = F\"ai_dance_models/ai_dance_128_dims/rnn\" \n",
        "img_path = F\"dataset/480_cleaned_14k_800x480/\"\n",
        "dense_dataset_path=\"dataset/dense_dataset.npy\"\n",
        "dataset_path=\"dataset/dataset.npy\"\n",
        "model_path=path+\"/model_weight.h5\"  \n",
        "rnn_model_path=path+'/best_acc_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkCv9iJJ5FGo",
        "colab_type": "code",
        "outputId": "6005406c-d6da-4d26-cd1f-371d335848c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# reset(path,False)\n",
        "reset(path,True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ai_dance_models/ai_dance_128_dims/rnn/acc', 'ai_dance_models/ai_dance_128_dims/rnn/out', 'ai_dance_models/ai_dance_128_dims/rnn/loss', 'ai_dance_models/ai_dance_128_dims/rnn/dense']\n",
            "do you really want to delete all folders i.e acc,loss,out (Y/N)?y\n",
            "reset sucessfull :['ai_dance_models/ai_dance_128_dims/rnn/acc', 'ai_dance_models/ai_dance_128_dims/rnn/out', 'ai_dance_models/ai_dance_128_dims/rnn/loss', 'ai_dance_models/ai_dance_128_dims/rnn/dense']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdR1k5UPm-G6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# data=encoded_data\n",
        "data=np.load(dense_dataset_path)\n",
        "train=data[:13000]\n",
        "test=data[13000:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNi0mwwTj4sW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(data,k):\n",
        "    print('len',data.shape[0])\n",
        "    dataX,dataY = [],[]\n",
        "    for i in range(data.shape[0] - k):\n",
        "        x = data[i:i+k]\n",
        "        y = data[i+k]\n",
        "        dataX.append(x)\n",
        "        dataY.append(y)\n",
        "    return np.array(dataX) , np.array(dataY)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1y8-YXSmasl",
        "colab_type": "code",
        "outputId": "e2347e22-d9ed-4b29-c661-482cb1774d96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "look_back = 10\n",
        "trainX ,trainY = create_dataset(train,look_back)\n",
        "testX ,testY = create_dataset(test,look_back)\n",
        "trainX.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len 13000\n",
            "len 1400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12990, 10, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-J1eaUQSGFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdJPBjPZj4tO",
        "colab_type": "code",
        "outputId": "68f80ff5-fb22-4a3a-f839-ca2c0fb0b439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "suffix=''\n",
        "encoded_dims=128\n",
        "def get_rnn():\n",
        "  rnn = Sequential()\n",
        "  rnn.add(LSTM(units = 512, return_sequences = True ,input_shape=trainX.shape[1:],))\n",
        "  rnn.add(Dropout(0.2))\n",
        "  rnn.add(LSTM(units = 256, return_sequences = True))\n",
        "  rnn.add(Dropout(0.2))\n",
        "  rnn.add(LSTM(units = 256, ))\n",
        "  rnn.add(Dropout(0.2))\n",
        "  rnn.add(Dense(128,activation='relu'))\n",
        "  rnn.build(input_shape=trainX.shape[1:])\n",
        "  return rnn\n",
        "rnn=get_rnn()\n",
        "rnn.summary()\n",
        "with open('{}/rnn{}.json'.format(path,suffix), 'w') as f:\n",
        "    f.write(rnn.to_json())\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "SVG(model_to_dot(rnn,show_shapes=True,show_layer_names=True,rankdir=\"TD\").create(prog='dot', format='svg'))\n",
        "from keras.utils import plot_model\n",
        "plot_model(rnn,show_shapes=True, to_file=path +'/rnn{}.png'.format(suffix))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_7 (LSTM)                (None, 10, 512)           1312768   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 10, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 10, 256)           787456    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 10, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               32896     \n",
            "=================================================================\n",
            "Total params: 2,658,432\n",
            "Trainable params: 2,658,432\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh7Pj5kOMGNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load saved model\n",
        "rnn=None\n",
        "from keras.models import model_from_json,load_model\n",
        "import json\n",
        "if load_saved_model==True:\n",
        "  rnn=load_model(path+'/rnn_weight.h5')\n",
        "  rnn.summary()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27AupfA_Rlat",
        "colab_type": "text"
      },
      "source": [
        "> ## Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqVZakVWuFVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# used to log training stats \n",
        "from keras.callbacks import Callback\n",
        "\n",
        "plot_after=5\n",
        "show_after=5\n",
        "save_after=3\n",
        "no_img_to_save=5\n",
        "class MyLogger(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "      self.i = 0\n",
        "      self.x = []\n",
        "      self.losses = []\n",
        "      self.val_losses = []\n",
        "      self.acc = []\n",
        "      self.val_acc = []\n",
        "      self.logs = []\n",
        "      \n",
        "      ac=decoder.predict(testY[:no_img_to_save])\n",
        "      num=0\n",
        "      for im in ac:\n",
        "        img=np.reshape(im,(120,200))\n",
        "        plt.imshow(img,cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.title(str('%04d orig'%(num)))\n",
        "        plt.savefig(path+'/out/'+str('%04d orig'%(num))+'.jpg')\n",
        "        num+=1\n",
        "\n",
        "\n",
        "    #save model and plot result after each epoch \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      sample()\n",
        "      epoch=epoch\n",
        "      self.logs.append(logs)\n",
        "      self.x.append(self.i)\n",
        "      self.losses.append(logs.get('loss'))\n",
        "      self.val_losses.append(logs.get('val_loss'))\n",
        "      self.acc.append(logs.get('acc'))\n",
        "      self.val_acc.append(logs.get('val_acc'))\n",
        "      self.i += 1\n",
        "      \n",
        "      if epoch%plot_after==0:\n",
        "        # LOSS         \n",
        "        plt.plot(self.x, self.losses, label=\"loss\")\n",
        "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
        "        plt.legend()\n",
        "        plt.savefig(\"{}/loss/graph_loss{}.png\".format(path,suffix))\n",
        "#         plt.show();\n",
        "        plt.close()\n",
        "#         ACC\n",
        "        plt.plot(self.x, self.acc, label=\"acc\")\n",
        "        plt.plot(self.x, self.val_acc, label=\"val_acc\")\n",
        "        plt.legend()\n",
        "        plt.savefig(\"{}/acc/graph_acc{}.png\".format(path,suffix))\n",
        "#         plt.show();\n",
        "        plt.close()\n",
        "   \n",
        "                \n",
        "      if epoch%save_after==0:\n",
        "        rnn.save(\"{}/rnn_weight {}.h5\".format(path,suffix))\n",
        "\n",
        "      with open('{}/log.txt'.format(path), 'a+') as f:\n",
        "          f.write('\\n#{} : {}'.format(epoch, logs))\n",
        "          \n",
        "      if epoch%plot_after==0:\n",
        "        testPredict = rnn.predict(testX[:no_img_to_save])\n",
        "        res=decoder.predict(testPredict)    \n",
        "        j=0\n",
        "        for im in res:\n",
        "          plt.close()\n",
        "          img=np.reshape(im,(120,200))\n",
        "          plt.imshow(img,cmap='gray')\n",
        "          plt.axis('off')\n",
        "          plt.title('epoch: '+str(epoch))\n",
        "          plt.savefig(path+'/out/'+str('%04d'%(j))+'.jpg')\n",
        "          plt.close()\n",
        "          j+=1\n",
        "\n",
        "          \n",
        "# correct one"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgKpJByDRrJw",
        "colab_type": "text"
      },
      "source": [
        "> ## Training Rnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsD_ieBWr6DD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "encoder=load_model(F\"ai_dance_models/ai_dance_128_dims/aec/encoder_best_val_acc_.h5\")\n",
        "decoder=load_model(F\"ai_dance_models/ai_dance_128_dims/aec/decoder_best_val_acc_.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kpl4-xEsZUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reset(path,True)\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau,CSVLogger\n",
        "from keras import optimizers\n",
        "cbk=MyLogger()\n",
        "bva= ModelCheckpoint(path+'/best_val_acc_model'+suffix+'.h5', monitor='val_acc', mode='max',save_best_only=True, save_weights_only=False)\n",
        "bvl= ModelCheckpoint(path+'/least_val_loss_model'+suffix+'.h5', monitor='val_loss', mode='min',save_best_only=True, save_weights_only=False)\n",
        "ba= ModelCheckpoint(path+'/best_acc_model.'+suffix+'h5', monitor='acc', mode='max',save_best_only=True, save_weights_only=False)\n",
        "bl= ModelCheckpoint(path+'/least_loss_model.'+suffix+'h5', monitor='loss', mode='min',save_best_only=True, save_weights_only=False)\n",
        "csv_logger = CSVLogger(path+'/training2.csv')\n",
        "if load_saved_model:\n",
        "  rnn=rnn\n",
        "else:\n",
        "  rnn=get_rnn()\n",
        "rnn.compile(loss = \"mse\",optimizer ='adam',metrics=['accuracy'],)\n",
        "\n",
        "# rnn.summary()\n",
        "batch_size = 128\n",
        "num_epoch = 10000\n",
        "# model training\n",
        "model_log = rnn.fit(trainX, trainY,\n",
        "            batch_size=batch_size,\n",
        "            epochs=num_epoch,\n",
        "            verbose=1,\n",
        "            validation_data=(testX,testY),\n",
        "            callbacks=[cbk,bva,bvl,ba,bl,csv_logger],\n",
        "            initial_epoch=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3HUEWo1L5Ux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import fabs\n",
        "def sample():\n",
        "#   rand=randint()\n",
        "  r=rnn.predict(testX[:1])\n",
        "  a=testY[:1]\n",
        "  for i in range(1):\n",
        "    print('*'*100)\n",
        "    for j in range(10):\n",
        "      print('%-12f%-12f%-12f'%(a[i][j],r[i][j],fabs(a[i][j]-r[i][j])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nu3ULb7qdaY",
        "colab_type": "text"
      },
      "source": [
        "> ## Result generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OfKxbRoLhSRk",
        "colab": {}
      },
      "source": [
        "load_dataset_from_npy = True \n",
        "load_saved_model=False  \n",
        "\n",
        "path = F\"ai_dance_models/ai_dance_128_dims/rnn\" \n",
        "img_path = F\"dataset/480_cleaned_14k_800x480/\"\n",
        "dense_dataset_path=\"dataset/dense_dataset.npy\"\n",
        "dataset_path=\"dataset/dataset.npy\"\n",
        "model_path=path+\"/model_weight.h5\"  \n",
        "rnn_model_path=path+'/best_acc_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXXardfb4jrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "encoder=load_model(F\"ai_dance_models/ai_dance_128_dims/aec/encoder_best_val_acc_.h5\")\n",
        "decoder=load_model(F\"ai_dance_models/ai_dance_128_dims/aec/decoder_best_val_acc_.h5\")\n",
        "rnn=load_model(F\"ai_dance_models/ai_dance_128_dims/rnn/best_val_acc_model_.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkG1h0XRu1IH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -r 'gdrive/My Drive/colab/ai_dance_models/testing/rnn_relu_activation/result'\n",
        "# !mkdir 'gdrive/My Drive/colab/ai_dance_models/testing/rnn_relu_activationn/result'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V5mDKxFaNU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rmtree(path+'/result')\n",
        "os.mkdir(path+'/result')\n",
        "# os.mkdir(path+'/video')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0FAtaNLL3ZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from shutil import rmtree\n",
        "def reset_result_folder():\n",
        "  res_folder=F'ai_dance_models/ai_dance_128_dims/rnn/result'\n",
        "  rmtree(res_folder)\n",
        "  os.mkdir(res_folder)\n",
        "  print('RESETEDDD ',res_folder,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsD2iLbhTHTm",
        "colab_type": "code",
        "outputId": "757103eb-9d42-42f0-b6d2-277491890e4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "reset_result_folder()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RESETEDDD  /content/gdrive/My Drive/colab/ai_dance_models/ai_dance_128_dims_10_lookup/rnn/result\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umHds7qba3z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_video(rate,fps,suffix):\n",
        "  rate=rate #8\n",
        "#   fps=rate\n",
        "  fps=fps #24\n",
        "  p='/'.join(path.split('/')[2:])\n",
        "  img_dir=p+'/result/%6d.jpg'\n",
        "  out_dir=p+'/video/result_rate_{}_fps_{}__{}.mp4'.format(rate,fps,suffix)\n",
        "  print('Making video: ',out_dir)\n",
        "  command=\"ffmpeg -r {} -i '{}' -c:v libx264 -vf fps={} -pix_fmt yuv420p '{}'\".format(rate,img_dir,fps,out_dir,)\n",
        "  print(command)\n",
        "  os.system(command)\n",
        "# print(os.system('ls' +path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oti8cj-P9JrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_dims=128\n",
        "look_back=10\n",
        "def new_seed(old_seed,new_dense):\n",
        "  \n",
        "  x=np.asarray(new_dense)\n",
        "  y=np.append(old_seed[0],x,axis=0)\n",
        "  y=np.delete(y,0,axis=0)\n",
        "  y=np.reshape(y,(1,look_back,encoded_dims))\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHcy2epD8l5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "\n",
        "def save_frame(im,frame_no):\n",
        "  if frame_no%500==0:\n",
        "    print(\"saved \",frame_no)\n",
        "    print('garbage collector:',gc.collect())\n",
        "  img=np.reshape(im,(120,200))\n",
        "  plt.imshow(img,cmap='gray')\n",
        "  plt.title(frame_no)\n",
        "  plt.axis('off')\n",
        "  plt.savefig(path+'/result/'+str('%06d'%(frame_no))+'.jpg')\n",
        "  plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QVt_XJS8OUxV",
        "colab": {}
      },
      "source": [
        "from random import randint\n",
        "def generate_result(frames=500,interpolation=False,random_n=0):\n",
        "  reset_result_folder()\n",
        "#   random_n=randint(0,len(testX)-1)\n",
        "  seed=np.random.rand(1,10,128)\n",
        "#   seed=testX[random_n:random_n+1]\n",
        "  frames=frames\n",
        "  interpolation_frames=10\n",
        "  video_rate=6\n",
        "  video_fps=30\n",
        "  \n",
        "  if interpolation==False:\n",
        "    for i in range(frames):\n",
        "      den=rnn.predict(seed)\n",
        "      frame=decoder.predict(den)\n",
        "      save_frame(frame,i)\n",
        "      seed=new_seed(seed,den)\n",
        "    suffix=\"seed:{} _ No interpolation\".format(random_n)\n",
        "    make_video(video_rate,video_rate,suffix)\n",
        "  else:\n",
        "    new_den=np.zeros((1,128))\n",
        "    old_den=np.zeros((1,128))\n",
        "    frames=frames*(interpolation_frames)\n",
        "    for i in range(0,frames,interpolation_frames):\n",
        "#       if i%1000==0:\n",
        "#         print(gc.get_count())\n",
        "#         print(gc.collect())\n",
        "      new_den=rnn.predict(seed)\n",
        "      inc=(new_den-old_den)/interpolation_frames\n",
        "      for interp_no in range(interpolation_frames):\n",
        "        mid=old_den+inc*(interp_no+1)\n",
        "        frame=decoder.predict(mid)\n",
        "        save_frame(frame,i)\n",
        "        i+=1\n",
        "      seed=new_seed(seed,new_den)\n",
        "      old_den=new_den\n",
        "    suffix=\"seed:{} _interpolated\".format(random_n)\n",
        "#     video_rate=video_rate*interpolation_frames\n",
        "    video_fps=120\n",
        "    video_rate=40\n",
        "    make_video(video_rate,video_fps,suffix)\n",
        "\n",
        "      \n",
        "      \n",
        "      \n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d5wfV0tKGTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed=np.random.rand(1,10,128)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycvCcx-vQ26Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1):\n",
        "#   random_n=randint(0,len(testX)-1)\n",
        "  random_n=1\n",
        "  print('Using seed:: ',random_n)\n",
        "  # print(\"********************************** Non interpolated **********************************\")\n",
        "  # generate_result(100,False,random_n)\n",
        "  print(\"********************************** interpolated **********************************\")\n",
        "  generate_result(100,True,random_n)\n",
        "  gc.collect()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-W9f4INepaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "zip_path='gdrive/My Drive/colab/ai_dance_models/ai_dance_128_dims_10_lookup'\n",
        "zip_name=zip_path+'/../rnn and result.zip'\n",
        "zip_command=\"zip -r '{}' '{}'\".format(zip_name,zip_path)\n",
        "print(zip_command)\n",
        "os.system(zip_command)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cocfPWnV938z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_img(im,frame_no):\n",
        "#   if frame_no%100==0:\n",
        "#     print(\"saved \",frame_no)\n",
        "  img=np.reshape(im,(120,200))\n",
        "  plt.imshow(img,cmap='gray')\n",
        "  plt.title(frame_no)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "#   plt.savefig(path+'/result/'+str('%04d'%(frame_no))+'.jpg')\n",
        "#   plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}